{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "def histograma(img):\n",
    "    WB = np.zeros(256)\n",
    "    WG = np.zeros(256)\n",
    "    WR = np.zeros(256)\n",
    "    \n",
    "    # Coleta as características da imagens\n",
    "    qntLinhas, qntColunas, c = img.shape\n",
    "    B = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    R = img[:,:,2]\n",
    "    \n",
    "    # Cria histograma dos valores dos pixels\n",
    "    for i in range(qntLinhas):\n",
    "        for j in range(qntColunas):\n",
    "            WB[B[i,j]] = WB[B[i,j]] + 1\n",
    "            WG[G[i,j]] = WG[G[i,j]] + 1\n",
    "            WR[R[i,j]] = WR[R[i,j]] + 1\n",
    "            \n",
    "    # Normaliza os valores do histograma\n",
    "    for i in range(256):\n",
    "        WB[i] = WB[i]/(qntLinhas*qntColunas)\n",
    "        WG[i] = WG[i]/(qntLinhas*qntColunas)\n",
    "        WR[i] = WR[i]/(qntLinhas*qntColunas)\n",
    "        \n",
    "    return np.append(np.append(WB,WG),WR)\n",
    "\n",
    "def compareHistImages(original, compare):\n",
    "    histOriginal = histograma(original)\n",
    "    histOutput = histograma(compare)\n",
    "\n",
    "    # Calcula distância Euclidiana\n",
    "    tamanhoVetor = len(histOriginal)\n",
    "    soma = 0\n",
    "    \n",
    "    for i in range(tamanhoVetor):\n",
    "        soma = soma + ((histOriginal[i]-histOutput[i])**2)\n",
    "        \n",
    "    return soma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#está dando errado se tentar pegar as imagens do path images\n",
    "files_path = [os.path.abspath(x) for x in os.listdir(\"./images/img400x_recorte_horizontal\") if x.endswith('.png')]\n",
    "print(files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diretorio, arquivo = path, filename = os.path.split(files_path[0])\n",
    "# print(arquivo)\n",
    "# img = cv2.imread(arquivo)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "images = []\n",
    "for i in files_path:\n",
    "    diretorio, arquivo = path, filename = os.path.split(i)\n",
    "    print(arquivo)\n",
    "    img = cv2.imread(arquivo)\n",
    "    images.append(img)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demora muito tempo para imagens menores que 400x\n",
    "stitcher = cv2.createStitcher()\n",
    "status, stitched = stitcher.stitch(images)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo stitcher do opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"output.png\", stitched)\n",
    "plt.imshow(stitched)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.drawKeypoints está com erro em opencv 4.x, utilizar versão 3.4.5.20\n",
    "a = []\n",
    "kps1 = []\n",
    "images = []\n",
    "\n",
    "# disable OpenCL to because of bug in ORB in OpenCV 3.1\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "for i in files_path:\n",
    "    diretorio, arquivo = path, filename = os.path.split(i)\n",
    "    img = cv2.imread(arquivo)\n",
    "    images.append(img)\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "\n",
    "    \n",
    "    keypoints, descriptors = orb.detectAndCompute(img, None)\n",
    "    a.append(descriptors)\n",
    "    kps1.append(keypoints)\n",
    "    print(type(keypoints[0]))\n",
    "#     img2 = cv2.drawKeypoints(img, keypoints, None, color=(0,255,0), flags=0)\n",
    "    a.append(descriptors)\n",
    "    kps1.append(keypoints)\n",
    "#     a.append(descriptors)\n",
    "#     img = cv2.drawKeypoints(img, keypoints, None)\n",
    "#     print(type(descriptors))\n",
    "    \n",
    "#     plt.imshow(img2)\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ORB\n",
    "\n",
    "print('OpenCV version: {}'.format(cv2.__version__) )\n",
    "\n",
    "\n",
    "## Load images\n",
    "queryImg = cv2.imread('img400x_2.png')\n",
    "trainImg = cv2.imread('img400x_1.png')\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(queryImg)\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(trainImg)\n",
    "\n",
    "## Convert to gray\n",
    "grayQuery = cv2.cvtColor(queryImg, cv2.COLOR_BGR2GRAY)\n",
    "grayTrain = cv2.cvtColor(trainImg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## Creating orb detector\n",
    "orb = cv2.ORB_create()\n",
    "# orb = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "\n",
    "## Finding KPs and Descs\n",
    "kpQuery, descQuery = orb.detectAndCompute(grayQuery, None)\n",
    "kpTrain, descTrain = orb.detectAndCompute(grayTrain, None)\n",
    "\n",
    "## Create Matcher\n",
    "# matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "matcher = cv2.BFMatcher()\n",
    "print('Creating Brute Force matcher')\n",
    "\n",
    "## Matching\n",
    "# matches = matcher.match(descQuery, descTrain)\n",
    "matches = matcher.knnMatch(descQuery, descTrain, k=2)\n",
    "\n",
    "# Apply ratio test\n",
    "good = []\n",
    "\n",
    "for m in matches:\n",
    "    if m[0].distance < 0.5*m[1].distance:\n",
    "        good.append(m)\n",
    "\n",
    "matches = np.asarray(good)\n",
    "\n",
    "# Extract location of good matches\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    points1[i, :] = kpQuery[match[0].queryIdx].pt\n",
    "    points2[i, :] = kpTrain[match[0].trainIdx].pt\n",
    "    \n",
    "# Find homography\n",
    "h, _ = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "print(h)\n",
    "\n",
    "\n",
    "\n",
    "# Use homography\n",
    "height, width, channels = trainImg.shape\n",
    "im1Reg = cv2.warpPerspective(queryImg, h, (trainImg.shape[1] + queryImg.shape[1], trainImg.shape[0]) )\n",
    "\n",
    "## Draw points\n",
    "result = cv2.drawMatchesKnn(grayQuery, kpQuery, grayTrain, kpTrain,  matches[:10], None, (255,0,0), flags=2)\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Stitching\n",
    "dst = cv2.warpPerspective(queryImg, h, (trainImg.shape[1] + queryImg.shape[1], trainImg.shape[0]) )\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Warped Image')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "\n",
    "dst[0:trainImg.shape[0], 0:trainImg.shape[1]] = trainImg\n",
    "cv2.imwrite('final.png',dst)\n",
    "plt.imshow(dst)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código referente ao repositorio \n",
    "\n",
    "https://github.com/kushalvyas/Python-Multiple-Image-Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010596568930581332\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "\n",
    "\n",
    "def checkBlack(pt):\n",
    "    return pt[0] == 0 and pt[1] == 0 and pt[2] == 0\n",
    "\n",
    "def blackBorder(image):\n",
    "    \n",
    "    w = None\n",
    "    h = None\n",
    "    \n",
    "    for y in range(len(image)):\n",
    "        if checkBlack(image[y][0]) and checkBlack(image[y+1][0]) and checkBlack(image[y+2][0]):\n",
    "            h = y - 1\n",
    "            break\n",
    "\n",
    "    for x in range(len(image[0])):\n",
    "        if checkBlack(image[0][x]) and checkBlack(image[0][x+1]) and checkBlack(image[0][x+2]):\n",
    "            w = x - 1\n",
    "            break\n",
    "                \n",
    "    return (w,h)\n",
    "\n",
    "def imageWithoutFirstColBlack(img):\n",
    "\n",
    "    w, h = blackBorder(img)\n",
    "    if not w or not h or w < 0 or h < 0:\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    final_image = np.zeros((h, w, 3), dtype=\"uint8\")\n",
    "\n",
    "    for y in range(len(final_image)):\n",
    "        for x in range(len(final_image[0])):\n",
    "            final_image[y][x] = img[y][x]\n",
    "\n",
    "    return final_image\n",
    "\n",
    "\n",
    "class FeatureFinder():\n",
    "    def __init__(self):\n",
    "        self.matcher = None\n",
    "        self.descriptor = None\n",
    "        self.matched_imgs = 0\n",
    "        self.name = 'd'\n",
    "        pass\n",
    "\n",
    "    def printMatches(self, img):\n",
    "        self.matched_imgs += 1\n",
    "        output = 'output/matches_'+ self.name + '_' + str(self.matched_imgs) +  '.png'\n",
    "        print(output)\n",
    "        cv2.imwrite(output, img )\n",
    "    \n",
    "    def getFeatures(self, im):\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = self.descriptor.detectAndCompute(gray, None)\n",
    "        return {\"kp\":kp, \"des\":des}\n",
    "    \n",
    "    def getMatches(self, img1, img2):\n",
    "        return []\n",
    "    \n",
    "    def getHomography(self, good, img1, img2):\n",
    "        return None\n",
    "\n",
    "\n",
    "class SIFT(FeatureFinder):\n",
    "    def __init__(self):\n",
    "        FeatureFinder.__init__(self)\n",
    "        self.descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "        self.matcher = cv2.BFMatcher()\n",
    "        self.name = 'SIFT'\n",
    "        \n",
    "    def getMatches(self, img1, img2):\n",
    "        self.images = [img1, img2]\n",
    "        \n",
    "        image_set_1 = self.getFeatures(img1)\n",
    "        image_set_2 = self.getFeatures(img2)\n",
    "        \n",
    "        matches = self.matcher.knnMatch(image_set_2['des'], image_set_1['des'], k=2)\n",
    "\n",
    "        # Apply ratio test\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.75*n.distance:\n",
    "                good.append([m])\n",
    "                \n",
    "        return good, image_set_1, image_set_2\n",
    "    \n",
    "    def showPoints(self, img1, img2):\n",
    "        \n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "        img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "        \n",
    "        draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "        img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "        pltShow(img3)\n",
    "    \n",
    "    def getHomography(self, good, img1, img2):\n",
    "        \n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "\n",
    "        \n",
    "        \n",
    "        ## extract the matched keypoints\n",
    "        src_pts  = np.float32([img1['kp'][m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "        dst_pts  = np.float32([img2['kp'][m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "        ## find homography matrix and do perspective transform\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        self.showPoints()\n",
    "        \n",
    "        return M\n",
    "\n",
    "        \n",
    "class SURF(FeatureFinder):\n",
    "    def __init__(self):\n",
    "        FeatureFinder.__init__(self)\n",
    "        self.descriptor = cv2.xfeatures2d.SURF_create()\n",
    "    \n",
    "        index_params = dict(algorithm=0, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        self.flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        self.name = 'SURF'\n",
    "        \n",
    "    def getMatches(self, img1, img2):\n",
    "        \n",
    "        image_set_1 = self.getFeatures(img1)\n",
    "        image_set_2 = self.getFeatures(img2)\n",
    "        \n",
    "        matches = self.flann.knnMatch(image_set_2[\"des\"], image_set_1[\"des\"], k=2)\n",
    "        \n",
    "        good = []\n",
    "        for i, (m, n) in enumerate(matches):\n",
    "            if m.distance < 0.7 * n.distance:\n",
    "                good.append((m.trainIdx, m.queryIdx))\n",
    "        \n",
    "        ## Draw matches\n",
    "        img3 = cv2.drawMatchesKnn(img2, image_set_2['kp'], img1, image_set_1['kp'], matches[:10], None, (0,255,255), flags=2)\n",
    "        img3 = imageWithoutFirstColBlack(img3)\n",
    "        pltShow(img3)\n",
    "        self.printMatches(img3)\n",
    "        \n",
    "        return good, image_set_1, image_set_2\n",
    "    \n",
    "    def getHomography(self, good, image_set_1, image_set_2):\n",
    "        \n",
    "        if len(good) > 4:\n",
    "            points_current = image_set_2[\"kp\"]\n",
    "            points_previous = image_set_1[\"kp\"]\n",
    "\n",
    "            matched_points_current = np.float32(\n",
    "                [points_current[i].pt for (__, i) in good]\n",
    "            )\n",
    "            matched_points_prev = np.float32(\n",
    "                [points_previous[i].pt for (i, __) in good]\n",
    "            )\n",
    "\n",
    "            H, _ = cv2.findHomography(\n",
    "                matched_points_current, matched_points_prev, cv2.RANSAC, 4\n",
    "            )\n",
    "            return H\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "class ORB(FeatureFinder):\n",
    "    def __init__(self):\n",
    "        FeatureFinder.__init__(self)\n",
    "        self.descriptor = cv2.ORB_create()\n",
    "        self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        self.images = []\n",
    "        self.name = 'ORB'\n",
    "    \n",
    "    def getFeatures(self, im):\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        kp = self.descriptor.detect(gray,None)\n",
    "        kp, des = self.descriptor.compute(gray, kp)\n",
    "        \n",
    "        return {\"kp\": kp, \"des\": des}\n",
    "    \n",
    "    def getMatches(self, img1, img2):\n",
    "        image_set_1 = self.getFeatures(img1)\n",
    "        image_set_2 = self.getFeatures(img2)\n",
    "        \n",
    "        self.images = [img1, img2]\n",
    "        \n",
    "        matches = self.matcher.match( image_set_2[\"des\"], image_set_1[\"des\"] )\n",
    "        good = sorted(matches, key = lambda x:x.distance)\n",
    "        \n",
    "        return good, image_set_1, image_set_2\n",
    "        \n",
    "    \n",
    "    def showPointAndStitch(self, queryImg, trainImg, H, kpQuery, kpTrain, matches):\n",
    "        result = cv2.drawMatches(queryImg, kpQuery, trainImg, kpTrain,  matches[:10], None, (0,255,0), flags=2)\n",
    "        result = imageWithoutFirstColBlack(result)\n",
    "        \n",
    "        pltShow(result)\n",
    "        self.printMatches(result)\n",
    "\n",
    "        dst = cv2.warpPerspective(queryImg, H, (trainImg.shape[1] + queryImg.shape[1], trainImg.shape[0]) )\n",
    "        \n",
    "        plt.subplot(122),plt.imshow(dst),plt.title('Warped Image')\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        \n",
    "        dst[0:trainImg.shape[0], 0:trainImg.shape[1]] = trainImg\n",
    "        pltShow(dst)\n",
    "    \n",
    "    def getHomography(self, good, img1, img2):\n",
    "        ## extract the matched keypoints\n",
    "        \n",
    "        kp1 = img2['kp']\n",
    "        kp2 = img1['kp']\n",
    "        \n",
    "        kps1 = [kp1[m.queryIdx].pt for m in good]\n",
    "        kps2 = [kp2[m.trainIdx].pt for m in good]\n",
    "        \n",
    "        src_pts  = np.float32( kps1 ).reshape(-1,1,2)\n",
    "        dst_pts  = np.float32( kps2 ).reshape(-1,1,2)\n",
    "\n",
    "        ## find homography matrix and do perspective transform\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        img1, img2 = self.images[:2]\n",
    "\n",
    "#         self.showPointAndStitch(img2, img1, M, kp1, kp2, good)\n",
    "        \n",
    "        return M\n",
    "        \n",
    "\n",
    "class Matcher:\n",
    "    def __init__(self, finder):\n",
    "        self.featureFinder = finder\n",
    "\n",
    "    def match(self, i1, i2):\n",
    "\n",
    "        good, image_set_1, image_set_2 = self.featureFinder.getMatches(i1, i2)\n",
    "    \n",
    "        H = self.featureFinder.getHomography(good, image_set_1, image_set_2)\n",
    "        \n",
    "        return H\n",
    "\n",
    "    def get_SURF_features(self, im):\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = self.featureFinder.detectAndCompute(gray, None)\n",
    "        return {\"kp\": kp, \"des\": des}\n",
    "\n",
    "\n",
    "class Stitcher:\n",
    "    def __init__(\n",
    "        self,\n",
    "        number_of_images,\n",
    "        finder = SURF()\n",
    "    ):\n",
    "\n",
    "        self.matcher_obj = Matcher(finder)\n",
    "        self.homography_cache = {}\n",
    "        self.overlay_cache = {}\n",
    "\n",
    "        self.count = number_of_images\n",
    "\n",
    "    def stitch(self, images=[]):\n",
    "        \"\"\"\n",
    "        stitches the images into a panorama\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "\n",
    "        self.prepare_lists()\n",
    "\n",
    "        # left stitching\n",
    "        start = timeit.default_timer()\n",
    "        self.left_shift()\n",
    "        self.right_shift()\n",
    "        stop = timeit.default_timer()\n",
    "        duration = stop - start\n",
    "        print(\"stitching took %.2f seconds.\" % duration)\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def prepare_lists(self):\n",
    "\n",
    "        # reset lists\n",
    "        self.left_list = []\n",
    "        self.right_list = []\n",
    "\n",
    "        self.center_index = int(self.count / 2)\n",
    "\n",
    "        self.result = self.images[self.center_index]\n",
    "\n",
    "        for i in range(self.count):\n",
    "            if i <= self.center_index:\n",
    "                self.left_list.append(self.images[i])\n",
    "            else:\n",
    "                self.right_list.append(self.images[i])\n",
    "\n",
    "    def get_homography(self, image_1, image_1_key, image_2, image_2_key, direction):\n",
    "        # TODO: use image indexes from the input array\n",
    "        \"\"\"\n",
    "        Calculate the homography matrix between two images.\n",
    "        Return from cache if possible.\n",
    "        Args:\n",
    "            image_1 (np.array) - first image\n",
    "            image_1_key (str) - identifier for cache\n",
    "            image_2 (np.array) - second image\n",
    "            image_2_key (str) - identifier for cache\n",
    "            direction (str) - \"left\" or \"right\"\n",
    "        Returns:\n",
    "            homography (np.array) - Homograpy Matrix\n",
    "        \"\"\"\n",
    "\n",
    "        cache_key = \"_\".join([image_1_key, image_2_key, direction])\n",
    "        homography = self.homography_cache.get(cache_key, None)\n",
    "        if homography is None:\n",
    "            # TODO: is the homography the same regardless of order??\n",
    "            homography = self.matcher_obj.match(image_1, image_2)\n",
    "            # put in cache\n",
    "            self.homography_cache[cache_key] = homography\n",
    "        return homography\n",
    "\n",
    "    def left_shift(self):\n",
    "        \"\"\"\n",
    "        stitch images center to left\n",
    "        \"\"\"\n",
    "        # start off with center image\n",
    "        a = self.left_list[0]\n",
    "\n",
    "        for i, image in enumerate(self.left_list[1:]):\n",
    "            H = self.get_homography(a, str(i), image, str(i + 1), \"left\")\n",
    "            \n",
    "            thresh = 500\n",
    "\n",
    "            # inverse homography\n",
    "            XH = np.linalg.inv(H)\n",
    "\n",
    "            ds = np.dot(XH, np.array([a.shape[1], a.shape[0], 1]))\n",
    "            ds = ds / ds[-1]\n",
    "\n",
    "            f1 = np.dot(XH, np.array([0, 0, 1]))\n",
    "            f1 = f1 / f1[-1]\n",
    "\n",
    "            XH[0][-1] += abs(f1[0])\n",
    "            XH[1][-1] += abs(f1[1])\n",
    "\n",
    "            ds = np.dot(XH, np.array([a.shape[1], a.shape[0], 1]))\n",
    "            offsety = abs(int(f1[1]))\n",
    "            offsetx = abs(int(f1[0]))\n",
    "\n",
    "            # dimension of warped image\n",
    "            dsize = (int(round(ds[0]))+ offsetx + thresh, int(round(ds[1])) + offsety + thresh)\n",
    "            \n",
    "            tmp = cv2.warpPerspective(a, XH, dsize)\n",
    "            \n",
    "            # punch the image in there\n",
    "            tmp[\n",
    "                offsety : image.shape[0] + offsety, offsetx : image.shape[1] + offsetx\n",
    "            ] = image\n",
    "\n",
    "            a = tmp\n",
    "\n",
    "            \n",
    "        print('left')\n",
    "        self.result = tmp\n",
    "\n",
    "    def right_shift(self):\n",
    "        \"\"\"\n",
    "        stitch images center to right\n",
    "        \"\"\"\n",
    "        for i, imageRight in enumerate(self.right_list):\n",
    "            imageLeft = self.result\n",
    "\n",
    "            H = self.get_homography(imageLeft, str(i), imageRight, str(i + 1), \"right\")\n",
    "\n",
    "            # args: original_image, matrix, output shape (width, height)\n",
    "            result = cv2.warpPerspective(\n",
    "                imageRight,\n",
    "                H,\n",
    "                (imageLeft.shape[1] + imageRight.shape[1], imageLeft.shape[0]),\n",
    "            )\n",
    "\n",
    "            mask = np.zeros((result.shape[0], result.shape[1], 3), dtype=\"uint8\")\n",
    "            mask[0 : imageLeft.shape[0], 0 : imageLeft.shape[1]] = imageLeft\n",
    "            self.result = self.blend_images(mask, result, str(i))\n",
    "        print('right')\n",
    "\n",
    "    def blend_images(self, background, foreground, i):\n",
    "        \"\"\"\n",
    "        inspired by this answer:\n",
    "        https://stackoverflow.com/a/54129424/1909378\n",
    "        \"\"\"\n",
    "\n",
    "        only_right = self.overlay_cache.get(i, None)\n",
    "        if only_right is None:\n",
    "            only_right = np.nonzero(\n",
    "                (np.sum(foreground, 2) != 0) * (np.sum(background, 2) == 0)\n",
    "            )\n",
    "            self.overlay_cache[i] = only_right\n",
    "\n",
    "        background[only_right] = foreground[only_right]\n",
    "        return background\n",
    "    \n",
    "    \n",
    "    \n",
    "## Atalho para mostrar imagens\n",
    "def pltShow(img, flag=False):\n",
    "    if flag:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "def experiment(count=1):\n",
    "    base_path = '/app/images/'\n",
    "    base_name  = 'image' + str(count)\n",
    "    group_name = 'grupo' + str(count) + '/'\n",
    "    \n",
    "    images_path = base_path + group_name\n",
    "    print(images_path)\n",
    "\n",
    "    imgs = []\n",
    "    path = images_path\n",
    "    valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "    for f in os.listdir(path):\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        if ext.lower() not in valid_images:\n",
    "            continue\n",
    "        imgs.append(os.path.join(path,f))\n",
    "    \n",
    "    imgs = sorted(imgs, key = lambda x:x)\n",
    "    \n",
    "    img = image_stitch(imgs)\n",
    "    cv2.imwrite(base_path + base_name + '_out' + '.png', img)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    original = cv2.imread(base_path + base_name + '.png')\n",
    "    soma = compareHistImages(original, img)\n",
    "    \n",
    "    print(base_name, soma)\n",
    "    \n",
    "    \n",
    "def image_stitch(files_path):\n",
    "    print(files_path)\n",
    "    s = Stitcher( len(files_path), ORB() )\n",
    "    \n",
    "    images = [ cv2.imread(f) for f in files_path ]\n",
    "    \n",
    "    for img in images:\n",
    "        pltShow(img)\n",
    "\n",
    "    panorama = s.stitch(images)\n",
    "    \n",
    "    img = imageWithoutFirstColBlack(panorama)\n",
    "\n",
    "    pltShow(panorama)\n",
    "    pltShow(img)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "#     for i in range(2,5):\n",
    "    experiment(5)\n",
    "    \n",
    "    \n",
    "#     soma = compareHistImages(\n",
    "#         cv2.imread('./images/image2.png'), \n",
    "#         cv2.imread('./images/image2_out_corrected.png'))\n",
    "    \n",
    "    print(soma)\n",
    "    \n",
    "#     path = \"./images/img400x_5_recorte_horizontal/\"\n",
    "#     path = \"./output/test-2/\"\n",
    "#     path = \"\"\n",
    "\n",
    "#     files_path = [os.path.abspath(x) for x in os.listdir(path) if x.endswith('.png')]\n",
    "#     files_path = sorted(files_path, key = lambda x:x)\n",
    "    \n",
    "#     img = image_stitch(files_path)\n",
    "#     cv2.imwrite('output/out.png', img)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
